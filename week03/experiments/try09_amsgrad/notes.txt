
optimizer type: Adam lr: 3e-05 
Other paramiters: ['betas: (0.9, 0.999)', 'eps: 1e-08', 'weight_decay: 0', 'amsgrad: True', 'maximize: False', 'foreach: None', 'capturable: False', 'differentiable: False', 'fused: None']   

EPOCHS: 250

Batchsize: train:32 dev:128

Dropout: 0.2
