
optimizer type: SGD lr: 0.001 
Other paramiters: ['momentum: 0.9', 'dampening: 0', 'weight_decay: 0.001', 'nesterov: False', 'maximize: False', 'foreach: None', 'differentiable: False', 'fused: None', 'initial_lr: 0.001']   

EPOCHS: 250

Batchsize: train:64 dev:128

Dropout: 0.5

scheduler type: MultiStepLR 
paramiters: ['milestones:Counter({30: 1})', 'gamma:10', 'base_lrs:[0.001]', 'last_epoch:0', 'verbose:False', '_get_lr_called_within_step:False', '_last_lr:[0.001]']

Dataset: FULL
