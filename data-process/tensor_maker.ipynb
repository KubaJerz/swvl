{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE\n",
    "The labels are `class, x, y, width, height`\n",
    "\n",
    "We *REMOVE* `class` so that its just `x, y, width, height`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_DIR = '/Users/kuba/Documents/data/raw/face-detection-dataset/labels'\n",
    "IMG_DIR = '/Users/kuba/Documents/data/raw/face-detection-dataset/images'\n",
    "\n",
    "train_file_names = '/Users/kuba/projects/swvl/data-process/single-faces/single_face_train.txt'\n",
    "test_file_names = '/Users/kuba/projects/swvl/data-process/single-faces/single_face_test.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_paths(names_path, class_type):\n",
    "    with open(names_path, 'r') as file_names:\n",
    "        names = file_names.readlines()\n",
    "        img_paths = [ IMG_DIR + \"/\" + class_type + \"/\" + name.strip() + \".jpg\" for name in names]\n",
    "        label_paths = [ LABEL_DIR + \"/\" + class_type + \"/\" + name.strip() + \".txt\" for name in names]\n",
    "    \n",
    "    return img_paths, label_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_paths, train_label_paths = make_paths(train_file_names, 'train')\n",
    "test_img_paths, test_label_paths = make_paths(test_file_names, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_pad_data(img_paths, label_paths, save_location,  target_size=(224, 224)):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(target_size, antialias=True),  # Resize all images to same dimensions\n",
    "    ])\n",
    "\n",
    "    transform_normal =  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "    for f_img, f_label in tqdm(list(zip(img_paths, label_paths))):\n",
    "        img = Image.open(f_img)\n",
    "        img_tensor = transform(img)\n",
    "        if img_tensor.size()[0] == 1:\n",
    "            img_tensor = img_tensor.repeat(3, 1, 1)\n",
    "\n",
    "        if img_tensor.size(0) == 4:\n",
    "            #keep only the first 3 channels (RGB)\n",
    "            img_tensor = img_tensor[:3, :, :]\n",
    "\n",
    "        if img_tensor.size()[0] != 3:\n",
    "            print(f_img)\n",
    "            print(img_tensor.shape)\n",
    "\n",
    "        img_tensor = transform_normal(img_tensor)\n",
    "\n",
    "        with open(f_label, 'r') as f:\n",
    "            label = f.readline().strip()\n",
    "            bbox = torch.tensor([float(x) for x in label.split()][1:])\n",
    "\n",
    "        name = f_img.split(\"/\")[-1].split(\".\")[0]\n",
    "        sav_name = save_location + \"/\" + name + \".pt\"\n",
    "        torch.save((img_tensor, bbox), sav_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5791/5791 [01:07<00:00, 85.21it/s] \n",
      "100%|██████████| 1469/1469 [00:16<00:00, 88.53it/s]\n"
     ]
    }
   ],
   "source": [
    "process_and_pad_data(train_img_paths, train_label_paths, '/Users/kuba/Documents/data/raw/single-face-tensors/train')\n",
    "process_and_pad_data(test_img_paths, test_label_paths, '/Users/kuba/Documents/data/raw/single-face-tensors/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "Individal process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_img = f'/home/kuba/Documents/data/raw/me-img/raw/sun.jpeg'\n",
    "# name = 'sun'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Resize((224,224), antialias=True)  # Resize all images to same dimensions\n",
    "# ])\n",
    "\n",
    "# transform_normal =  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# img = Image.open(f_img)\n",
    "# img_tensor = transform(img)\n",
    "# img_tensor = transform_normal(img_tensor)\n",
    "\n",
    "# torch.save(img_tensor, f'/home/kuba/Documents/data/raw/me-img/tensor/{name}.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
